{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79033,"status":"ok","timestamp":1719245780351,"user":{"displayName":"Sourav Debnath","userId":"06249564259746657035"},"user_tz":-360},"id":"QPmpIxi5YuJb","outputId":"582b8ead-1173-4c74-de89-ed4fee842ef5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.41 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 30.2/78.2 GB disk)\n"]}],"source":["%pip install ultralytics\n","\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bATdSpRnM_B"},"outputs":[],"source":["# for delete a folder\n","#!rm -r /content/runs/detect/train"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":529,"status":"ok","timestamp":1719245801247,"user":{"displayName":"Sourav Debnath","userId":"06249564259746657035"},"user_tz":-360},"id":"yu3oSP2Fa4-3"},"outputs":[],"source":["import os\n","from ultralytics import YOLO\n","from IPython.display import display, Image\n","from IPython import display\n","display.clear_output()"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":471,"status":"ok","timestamp":1719245804037,"user":{"displayName":"Sourav Debnath","userId":"06249564259746657035"},"user_tz":-360},"id":"qcb4JcC8ByIa"},"outputs":[],"source":["# set up environment\n","os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":915},"executionInfo":{"elapsed":8833,"status":"ok","timestamp":1719245816768,"user":{"displayName":"Sourav Debnath","userId":"06249564259746657035"},"user_tz":-360},"id":"5KiRxqPJa9Fh","outputId":"5216d5ff-27f5-42a7-f17c-79d3f4491854"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting roboflow\n","  Downloading roboflow-1.1.33-py3-none-any.whl (75 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.6.2)\n","Collecting chardet==4.0.0 (from roboflow)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n","Requirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy\u003e=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n","Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n","Requirement already satisfied: Pillow\u003e=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: urllib3\u003e=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.4)\n","Requirement already satisfied: PyYAML\u003e=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-magic (from roboflow)\n","  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (1.2.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (4.53.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (24.1)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (3.1.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eroboflow) (3.3.2)\n","Installing collected packages: python-magic, python-dotenv, chardet, requests-toolbelt, roboflow\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","Successfully installed chardet-4.0.0 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.33\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"3f81b1c4bed84a26b5ed6b63b9b3ccfc","pip_warning":{"packages":["chardet"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Dependency ultralytics==8.0.196 is required but found version=8.2.41, to fix: `pip install ultralytics==8.0.196`\n"]},{"name":"stderr","output_type":"stream","text":["Downloading Dataset Version Zip in /content/datasets/Object_Detection-7 to yolov8:: 100%|██████████| 30556/30556 [00:00\u003c00:00, 36541.90it/s]"]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["\n","Extracting Dataset Version Zip to /content/datasets/Object_Detection-7 in yolov8:: 100%|██████████| 1510/1510 [00:00\u003c00:00, 5209.90it/s]\n"]}],"source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"5at1DA83HbPcqs7WY5AA\")\n","project = rf.workspace(\"data-augmentation-j8vro\").project(\"object_detection-3xi6d\")\n","version = project.version(7)\n","dataset = version.download(\"yolov8\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402686,"status":"ok","timestamp":1719246439498,"user":{"displayName":"Sourav Debnath","userId":"06249564259746657035"},"user_tz":-360},"id":"w6tIgZxJb3oO","outputId":"0d8158e9-a1c8-4c32-aee0-37784fdf8dfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n","100% 49.7M/49.7M [00:00\u003c00:00, 326MB/s]\n","Ultralytics YOLOv8.2.41 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/datasets/Object_Detection-7/data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00\u003c00:00, 22.1MB/s]\n","Overriding model.yaml nc=80 with nc=3\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3777433  ultralytics.nn.modules.head.Detect           [3, [192, 384, 576]]          \n","Model summary: 295 layers, 25858057 parameters, 25858041 gradients, 79.1 GFLOPs\n","\n","Transferred 469/475 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","100% 6.23M/6.23M [00:00\u003c00:00, 121MB/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/Object_Detection-7/train/labels... 588 images, 0 backgrounds, 0 corrupt: 100% 588/588 [00:00\u003c00:00, 1833.04it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/Object_Detection-7/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Object_Detection-7/valid/labels... 115 images, 0 backgrounds, 0 corrupt: 100% 115/115 [00:00\u003c00:00, 1650.78it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/Object_Detection-7/valid/labels.cache\n","Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/20      7.18G      1.446      2.838      1.617         40        640: 100% 37/37 [00:24\u003c00:00,  1.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03\u003c00:00,  1.18it/s]\n","                   all        115        160      0.408      0.234      0.195     0.0722\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/20      7.01G      1.725      2.557      1.854         22        640: 100% 37/37 [00:20\u003c00:00,  1.83it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.25it/s]\n","                   all        115        160    0.00325      0.131    0.00133   0.000383\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/20      7.13G      1.918       2.72      2.043         19        640: 100% 37/37 [00:19\u003c00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02\u003c00:00,  1.75it/s]\n","                   all        115        160    0.00319      0.305    0.00312   0.000828\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/20      6.99G      1.939      2.726      2.079         30        640: 100% 37/37 [00:19\u003c00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02\u003c00:00,  1.62it/s]\n","                   all        115        160     0.0192      0.351     0.0144    0.00366\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/20       7.1G      1.962      2.655      2.076         37        640: 100% 37/37 [00:19\u003c00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.33it/s]\n","                   all        115        160    0.00529      0.504    0.00804    0.00308\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/20      7.08G      1.857      2.554      1.973         45        640: 100% 37/37 [00:19\u003c00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.30it/s]\n","                   all        115        160      0.221        0.3      0.186     0.0644\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/20      7.08G      1.733       2.49      1.883         23        640: 100% 37/37 [00:19\u003c00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.03it/s]\n","                   all        115        160      0.309       0.45      0.311       0.13\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/20      6.98G      1.753      2.335      1.859         32        640: 100% 37/37 [00:19\u003c00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.43it/s]\n","                   all        115        160      0.508       0.44      0.423      0.219\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/20      7.08G       1.62      2.116      1.791         37        640: 100% 37/37 [00:19\u003c00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.48it/s]\n","                   all        115        160      0.583      0.427      0.509      0.285\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/20      7.09G      1.549      2.034      1.727         33        640: 100% 37/37 [00:19\u003c00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02\u003c00:00,  1.96it/s]\n","                   all        115        160       0.52      0.585      0.576       0.32\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/20      7.09G      1.587      2.008      1.844         16        640: 100% 37/37 [00:20\u003c00:00,  1.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02\u003c00:00,  1.68it/s]\n","                   all        115        160      0.505      0.596      0.538      0.304\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/20      6.98G      1.544      1.835      1.823         17        640: 100% 37/37 [00:19\u003c00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.43it/s]\n","                   all        115        160      0.651      0.599      0.639      0.372\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/20      7.08G      1.451      1.723      1.733         17        640: 100% 37/37 [00:19\u003c00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.39it/s]\n","                   all        115        160       0.58      0.475      0.527      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/20      7.07G       1.45        1.6      1.738         18        640: 100% 37/37 [00:19\u003c00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02\u003c00:00,  1.90it/s]\n","                   all        115        160      0.619      0.702      0.681      0.417\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/20      7.08G      1.395      1.505        1.7         16        640: 100% 37/37 [00:19\u003c00:00,  1.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.44it/s]\n","                   all        115        160      0.688      0.699      0.703      0.458\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/20         7G      1.319      1.463      1.627         15        640: 100% 37/37 [00:19\u003c00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.44it/s]\n","                   all        115        160      0.727      0.745      0.738      0.501\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/20      7.08G      1.265      1.377      1.567         18        640: 100% 37/37 [00:19\u003c00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.47it/s]\n","                   all        115        160      0.748      0.728       0.74      0.482\n","      18/20      7.07G      1.229      1.303      1.533         18        640: 100% 37/37 [00:19\u003c00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.15it/s]\n","                   all        115        160      0.787      0.747      0.752       0.51\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/20      7.09G      1.184      1.258       1.52         16        640: 100% 37/37 [00:19\u003c00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.41it/s]\n","                   all        115        160      0.817       0.75      0.779      0.524\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/20      6.99G      1.157      1.176      1.478         16        640: 100% 37/37 [00:20\u003c00:00,  1.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01\u003c00:00,  2.44it/s]\n","                   all        115        160      0.852       0.75      0.789       0.54\n","\n","20 epochs completed in 0.153 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 52.0MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 52.0MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics YOLOv8.2.41 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 218 layers, 25841497 parameters, 0 gradients, 78.7 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:04\u003c00:00,  1.18s/it]\n","                   all        115        160      0.853       0.75      0.789       0.54\n","                mobile         41         43      0.952      0.953      0.964      0.729\n","                   pen         36         61      0.758      0.492      0.492       0.28\n","               scissor         38         56      0.848      0.804      0.911       0.61\n","Speed: 0.3ms preprocess, 10.5ms inference, 0.0ms loss, 9.9ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["!yolo task=detect mode=train model=yolov8m.pt data={dataset.location}/data.yaml epochs=20 imgsz=640"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18554,"status":"ok","timestamp":1719246501133,"user":{"displayName":"Sourav Debnath","userId":"06249564259746657035"},"user_tz":-360},"id":"BnkQiKrP7Rlh","outputId":"00ab9882-ef11-46f0-8863-4f8c97d58450"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.41 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 218 layers, 25841497 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Object_Detection-7/valid/labels.cache... 115 images, 0 backgrounds, 0 corrupt: 100% 115/115 [00:00\u003c?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:05\u003c00:00,  1.49it/s]\n","                   all        115        160      0.853       0.75      0.789       0.54\n","                mobile         41         43      0.951      0.953      0.964      0.728\n","                   pen         36         61      0.758      0.492      0.492       0.28\n","               scissor         38         56      0.849      0.804      0.911       0.61\n","Speed: 4.1ms preprocess, 23.4ms inference, 0.0ms loss, 8.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/val\n"]}],"source":["!yolo task=detect mode=val model=/content/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9195,"status":"ok","timestamp":1719246512618,"user":{"displayName":"Sourav Debnath","userId":"06249564259746657035"},"user_tz":-360},"id":"6MfZFgr27SR0","outputId":"4a84f681-7e88-4028-eee6-3af48c6b4b65"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.41 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 218 layers, 25841497 parameters, 0 gradients, 78.7 GFLOPs\n","\n","image 1/46 /content/datasets/Object_Detection-7/test/images/08_jpg.rf.a9bbc2b1690e7d5ffe45ccae77fa8fd4.jpg: 640x640 2 mobiles, 38.6ms\n","image 2/46 /content/datasets/Object_Detection-7/test/images/15_jpg.rf.843748ab7c78520a2ea6768fcc8dca20.jpg: 640x640 1 mobile, 37.1ms\n","image 3/46 /content/datasets/Object_Detection-7/test/images/27_jpg.rf.5d3905cd3d979a41b38cd2ff86d86658.jpg: 640x640 1 mobile, 37.0ms\n","image 4/46 /content/datasets/Object_Detection-7/test/images/Mobile_0_jpg.rf.73503c3a73b07838a79ea597575aa0d2.jpg: 640x640 1 mobile, 37.0ms\n","image 5/46 /content/datasets/Object_Detection-7/test/images/Mobile_21_jpg.rf.dcb7d6c45306c01a142902293ed9d382.jpg: 640x640 1 pen, 37.0ms\n","image 6/46 /content/datasets/Object_Detection-7/test/images/Mobile_24_jpg.rf.c891af395759b1bef4b8072d8d0bacd6.jpg: 640x640 1 mobile, 35.7ms\n","image 7/46 /content/datasets/Object_Detection-7/test/images/Mobile_2_jpg.rf.dcf412bddb4453c587deb146a56564ac.jpg: 640x640 1 mobile, 24.1ms\n","image 8/46 /content/datasets/Object_Detection-7/test/images/Mobile_3_jpg.rf.efb8c80c4353f259b83fce4d039bc570.jpg: 640x640 1 pen, 24.1ms\n","image 9/46 /content/datasets/Object_Detection-7/test/images/Mobile_9_jpg.rf.8b03c4126b82bc022dfb07e95b214c20.jpg: 640x640 1 pen, 23.4ms\n","image 10/46 /content/datasets/Object_Detection-7/test/images/WhatsApp-Image-2022-12-21-at-05-12-14-2-_jpeg_jpg.rf.9b31f3315ac73d6fa4df110d67afe809.jpg: 640x640 (no detections), 24.9ms\n","image 11/46 /content/datasets/Object_Detection-7/test/images/WhatsApp-Image-2022-12-21-at-05-13-01-1-_jpeg_jpg.rf.ca3e0578b321e214410b9613d26f854c.jpg: 640x640 1 scissor, 20.3ms\n","image 12/46 /content/datasets/Object_Detection-7/test/images/WhatsApp-Image-2022-12-21-at-05-13-06_jpeg_jpg.rf.912513a482c7d239871796141ef271b5.jpg: 640x640 (no detections), 20.2ms\n","image 13/46 /content/datasets/Object_Detection-7/test/images/WhatsApp-Image-2022-12-21-at-05-13-35-1-_jpeg_jpg.rf.ef0c2bf9a3a3c7e7f0528a77eb387883.jpg: 640x640 (no detections), 20.2ms\n","image 14/46 /content/datasets/Object_Detection-7/test/images/WhatsApp-Image-2022-12-21-at-05-14-50-1-_jpeg_jpg.rf.1703a4c6162f380755b9b97150253bda.jpg: 640x640 (no detections), 19.6ms\n","image 15/46 /content/datasets/Object_Detection-7/test/images/aleksandar-zivkovic-S2iQ9Wpj440-unsplash_jpg.rf.cb493492ca39bda1bb455c9f18b28e61.jpg: 640x640 3 scissors, 19.6ms\n","image 16/46 /content/datasets/Object_Detection-7/test/images/aleksandar-zivkovic-c18q3myyHLU-unsplash_jpg.rf.a5f17bc85f19239aad8ee929f8751a65.jpg: 640x640 1 scissor, 18.3ms\n","image 17/46 /content/datasets/Object_Detection-7/test/images/gabriel-5AzWcVjFrJY-unsplash_jpg.rf.a825a1d70bd04c711768d79db29fce53.jpg: 640x640 1 pen, 1 scissor, 18.2ms\n","image 18/46 /content/datasets/Object_Detection-7/test/images/micheile-henderson-L8wh7FCu4UQ-unsplash_jpg.rf.50792c2b06f1e5a43e038972f1f361a1.jpg: 640x640 1 scissor, 18.8ms\n","image 19/46 /content/datasets/Object_Detection-7/test/images/phones113_png.rf.383ed7228df4652bf564e1043f2c7bdf.jpg: 640x640 1 mobile, 18.2ms\n","image 20/46 /content/datasets/Object_Detection-7/test/images/phones116_png.rf.58669d14c438aaff5621a6b4c5ed30bd.jpg: 640x640 1 mobile, 17.6ms\n","image 21/46 /content/datasets/Object_Detection-7/test/images/phones122_png.rf.e00abc86a7fea8184fb35e9ee11bd033.jpg: 640x640 1 mobile, 18.8ms\n","image 22/46 /content/datasets/Object_Detection-7/test/images/phones128_png.rf.a58df35993d779085f9360522ceb4457.jpg: 640x640 1 mobile, 18.5ms\n","image 23/46 /content/datasets/Object_Detection-7/test/images/phones135_png.rf.e3a22654e89946577434ab9f1a38b9e7.jpg: 640x640 1 mobile, 17.8ms\n","image 24/46 /content/datasets/Object_Detection-7/test/images/phones161_png.rf.14768201e840ffc166ad22815ad63180.jpg: 640x640 1 mobile, 19.5ms\n","image 25/46 /content/datasets/Object_Detection-7/test/images/phones165_png.rf.1ad3a682212643a3a29901322bc82fe9.jpg: 640x640 1 mobile, 18.7ms\n","image 26/46 /content/datasets/Object_Detection-7/test/images/phones167_png.rf.705fd2831830e18e22343503b3550256.jpg: 640x640 1 mobile, 17.9ms\n","image 27/46 /content/datasets/Object_Detection-7/test/images/phones186_png.rf.1cd0d1cc20bc5c86bd3109670af6e6d6.jpg: 640x640 1 mobile, 19.1ms\n","image 28/46 /content/datasets/Object_Detection-7/test/images/phones193_png.rf.28aa58acacfce4503e9f1b54a6db3a75.jpg: 640x640 (no detections), 18.1ms\n","image 29/46 /content/datasets/Object_Detection-7/test/images/phones23_png.rf.9e1f4df6eb7f236ef175c50836aacb65.jpg: 640x640 1 mobile, 19.1ms\n","image 30/46 /content/datasets/Object_Detection-7/test/images/phones24_png.rf.1077e17f42965cd0a580166d5813d173.jpg: 640x640 (no detections), 18.6ms\n","image 31/46 /content/datasets/Object_Detection-7/test/images/phones30_png.rf.bbc7c29e19ed07d6df15efa79616254c.jpg: 640x640 1 mobile, 18.0ms\n","image 32/46 /content/datasets/Object_Detection-7/test/images/phones46_png.rf.116199369bbb497bc7b450a46f83c051.jpg: 640x640 (no detections), 19.2ms\n","image 33/46 /content/datasets/Object_Detection-7/test/images/phones6_png.rf.0976b9b712fd92289c3f04f004429bf3.jpg: 640x640 1 mobile, 18.1ms\n","image 34/46 /content/datasets/Object_Detection-7/test/images/phones76_png.rf.c0b6980ed309a6b17d811903dfb3cfe6.jpg: 640x640 1 mobile, 18.8ms\n","image 35/46 /content/datasets/Object_Detection-7/test/images/phones78_png.rf.ecaac20b89a7d499002fba96112968bb.jpg: 640x640 1 mobile, 18.3ms\n","image 36/46 /content/datasets/Object_Detection-7/test/images/rebecca-matthews-KW7TTx8JFvE-unsplash_jpg.rf.96b0e24b3e76e2605dd56d005296395e.jpg: 640x640 (no detections), 17.7ms\n","image 37/46 /content/datasets/Object_Detection-7/test/images/separado11_jpg.rf.611f6c639adcf56ecb6abbabfc3ff5e8.jpg: 640x640 2 scissors, 17.8ms\n","image 38/46 /content/datasets/Object_Detection-7/test/images/separado17_jpg.rf.241e5cbad4e7718a97b2a512615a4e06.jpg: 640x640 3 scissors, 19.0ms\n","image 39/46 /content/datasets/Object_Detection-7/test/images/separado6_jpg.rf.50f3eec1912474252f519aca63aa892c.jpg: 640x640 2 scissors, 18.4ms\n","image 40/46 /content/datasets/Object_Detection-7/test/images/separado71_jpg.rf.7af4d790507b259e6c7e7541846ef6c8.jpg: 640x640 1 scissor, 17.6ms\n","image 41/46 /content/datasets/Object_Detection-7/test/images/separado89_jpg.rf.42103b5bf010ef47644d11e22f60a64b.jpg: 640x640 2 scissors, 18.0ms\n","image 42/46 /content/datasets/Object_Detection-7/test/images/separado92_jpg.rf.7e3e85d16730dda409ce3719ede33db6.jpg: 640x640 2 scissors, 19.1ms\n","image 43/46 /content/datasets/Object_Detection-7/test/images/separado94_jpg.rf.d72e21ec8367e16b9492a2cd382a8b06.jpg: 640x640 2 scissors, 18.4ms\n","image 44/46 /content/datasets/Object_Detection-7/test/images/steve-johnson-8UmEJI_MJyk-unsplash_jpg.rf.c1bd70ae980f2306699e7947c861bab6.jpg: 640x640 1 scissor, 17.8ms\n","image 45/46 /content/datasets/Object_Detection-7/test/images/tesourareta158_jpg.rf.aef55dade442a6f8a72768899e69775c.jpg: 640x640 1 scissor, 19.0ms\n","image 46/46 /content/datasets/Object_Detection-7/test/images/tesourareta164_jpg.rf.3f33e84d4f4ed9bb6c374a6161aae6e2.jpg: 640x640 1 scissor, 18.3ms\n","Speed: 1.7ms preprocess, 21.5ms inference, 22.4ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["!yolo task=detect mode=predict model=/content/runs/detect/train/weights/best.pt conf=0.5 source={dataset.location}/test/images"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24712,"status":"ok","timestamp":1719246552006,"user":{"displayName":"Sourav Debnath","userId":"06249564259746657035"},"user_tz":-360},"id":"uulj0-1hiy3K","outputId":"28f66019-b509-45f9-e511-758dad99ae57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":490,"status":"ok","timestamp":1719246582505,"user":{"displayName":"Sourav Debnath","userId":"06249564259746657035"},"user_tz":-360},"id":"HXgG84OmjKQg"},"outputs":[],"source":["#for download best.pt file\n","!cp -r /content/runs/detect/train/weights/best.pt /content/drive/MyDrive/outputs/"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNFJBqjVu/GRjOwWpM2Gkr1","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}